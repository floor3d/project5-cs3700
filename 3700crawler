#!/usr/bin/env python3

import argparse
import socket
import urllib.parse
from html.parser import HTMLParser
import xml
import ssl
import time
import sys

DEFAULT_SERVER = "proj5.3700.network"
DEFAULT_PORT = 443

class Crawler:
    def __init__(self, args):
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password
        self.pages = {} # listof {url, visited} -- url and if it has been visited already
        self.csrf = "" #csrf token to include in each request
        self.sessid = "" #sessid to include in each request
        self.csrfmiddleware = "" #middleware token to include in logins
        self.flags = [] # flags to print at the end


    def run(self):
        #get csrf token
        request = "GET /accounts/login/ HTTP/1.1\r\n"
        request +="Host: %s\r\n" % self.server
        request +="Connection: close\r\n"
        request +="\r\n"

#        print("Request to %s:%d" % (self.server, self.port))
#        print(request)

        decoded = self.send_msg(request)
        
#        print(decoded)
        #find csrf token and sessionid to use in login
        parser = MyHTMLParser()
        parser.feed(decoded)
        csrf_idx = decoded.index("csrftoken")
        end_csrf_idx = decoded.index(";", csrf_idx)
        csrf = decoded[csrf_idx + 10:end_csrf_idx]
        self.csrf = csrf
                
        sessid_idx = decoded.index("sessionid")
        end_sessid_idx = decoded.index(";", sessid_idx)
        sessid = decoded[sessid_idx + 10:end_sessid_idx]
        if(parser.csrf == ""):
            self.run()
            return
        self.login(csrf, parser.csrf, sessid)

    
    #sends message to server: establish tls connection & send message
    def send_msg(self, request):
        context = ssl.create_default_context()
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            with context.wrap_socket(sock, server_hostname=self.server) as mysocket:
                mysocket.connect((self.server, self.port))
                mysocket.send(request.encode('ascii'))
#                print(request)

                data = mysocket.recv(16384)
            
                decoded = data.decode('ascii')
#                print("Response:\n%s" % decoded)
                #return the server's response
                return decoded


    #log in to fakebook
    def login(self, csrf, csrfmiddleware, sessid):
        self.csrfmiddleware = csrfmiddleware
        next_str = "&next=%2Ffakebook%2F"
        form_data = "username=%s&password=%s&csrfmiddlewaretoken=%s" % (self.username, self.password, csrfmiddleware)
        form_data += next_str
        request = "POST /accounts/login/ HTTP/1.1\r\n"
        request +="Host: %s:%s\r\n" % (self.server, self.port)
        request +="Connection: close\r\n"
#        request +="Origin: https://proj5.3700.network\r\n"
        request +="Content-Type: application/x-www-form-urlencoded\r\n"
#        request +="Referer: https://proj5.3700.network/accounts/login/\r\n"
        request +="Cookie: csrftoken=%s; sessionid=%s\r\n" % (self.csrf, sessid)
        request +="Content-Length: %s\r\n" % str(len(form_data))
        request +="\r\n"
        request += form_data
        request +="\r\n"
#        print(request)
        decoded = self.send_msg(request)
        self.csrf = csrf
        self.sessid = sessid
        self.crawl()


    #crawl site. find anchor tags, add to list, crawl them too.
    def crawl(self):
#        print("*" * 100)
        pagesToAdd = []
        #first step: gather pages from first page
        decoded = self.send_http("/")
        pagesToAdd.extend(self.parsePage(decoded))
        
        for url in pagesToAdd:
            self.pages[url] = False
        pagesToAdd.clear()

        #second step: start crawling
        while (len(self.flags) < 5):
            for url in self.pages:
                if not self.pages[url]:
                    decoded = ""
                    while "<" not in decoded:
                        decoded = self.send_http(url)
                    pages = self.parsePage(decoded)
                    pagesToAdd.extend(pages)
                    self.pages[url] = True
            for url in pagesToAdd:
                #add to dictionary list
                self.pages[url] = False
            pagesToAdd.clear()
        if(len(self.flags) == 5):
            # we are finished
            for flag in self.flags:
                print(flag)
            sys.exit(0)


    #extract all necessary data from html response, including session id, flags, and anchors
    def parsePage(self, decoded):
        ret = []
        if(decoded is None):
            return []
        if("sessionid" in decoded):
            sessid_idx = decoded.index("sessionid")
            end_sessid_idx = decoded.index(";", sessid_idx)
            self.sessid = decoded[sessid_idx + 10:end_sessid_idx]
        if("csrftoken" in decoded):
#            print("%&%&" * 25)
            csrftoken_idx = decoded.index("csrftoken")
            end_csrftoken_idx = decoded.index(";", csrftoken_idx)
            self.csrf = decoded[csrftoken_idx + 10:end_csrftoken_idx]
        parser = MyHTMLParser()
        parser.feed(decoded)
        if(len(parser.flags) > 0):
            for flag in parser.flags:
                #found a flag, add it if it's not there yet (this shouldn't happen but just in case)
                if flag not in self.flags:
                    self.flags.append(flag)
        for url in parser.anchors:
            if url not in self.pages:
                ret.append(url)
        return ret
        

    #send an http GET (or post if necessary) to the given url
    def send_http(self, url):
        request = "GET %s HTTP/1.1\r\n" % url
        if("login" in url):
            request = "POST %s HTTP/1.1\r\n" % url
        request +="Host: %s:%s\r\n" % (self.server, self.port)
        #ensure connection close. we remake connection every time
        request += "Connection: close\r\n"
        request +="Cookie: csrftoken=%s; sessionid=%s\r\n" % (self.csrf, self.sessid)
        if("login" in url):
            #need to log in. we need to send form data
            next_str = "&next=%2Ffakebook%2F"
            form_data = "username=%s&password=%s&csrfmiddlewaretoken=%s" % (self.username, self.password, self.csrfmiddleware)
            form_data += next_str
            request +="Content-Type: application/x-www-form-urlencoded\r\n"
            request +="Content-Length: %s\r\n" % str(len(form_data))
            request += "\r\n"
            request += form_data

        request +="\r\n"
        decoded = self.send_msg(request) 
#        print("the decoded response is" + " ^" * 50)
#        print(decoded)
#        print("^" * 50)
        if("sessionid" in decoded):
            sessid_idx = decoded.index("sessionid")
            end_sessid_idx = decoded.index(";", sessid_idx)
            self.sessid = decoded[sessid_idx + 10:end_sessid_idx]
        if("csrftoken" in decoded):
#            print("%"*100)
            csrftoken_idx = decoded.index("csrftoken")
            end_csrftoken_idx = decoded.index(";", csrftoken_idx)
            self.csrf = decoded[csrftoken_idx + 10:end_csrftoken_idx]

        #handle special codes

        if "302 Found" in decoded:
            # gives us another location to search
            location = decoded.index("Location")
            endl = decoded.index("\r\n", location)
            uri = decoded[location + 10:endl]
            if("csrftoken" in decoded):
                csrftoken_idx = decoded.index("csrftoken")
                end_csrftoken_idx = decoded.index(";", csrftoken_idx)
                self.csrf = decoded[csrftoken_idx + 10:end_csrftoken_idx]
            return self.send_http(uri)
        elif "403 Forbidden" in decoded or "404 Not Found" in decoded:
            #something went wrong. drop it
            return None
        elif "503 Service Unavailable" in decoded:
            #try again until it works
            return self.send_http(url)
        return decoded


#html parser class. extracts csrf token, anchor tag values, and flags
class MyHTMLParser(HTMLParser):
    def __init__(self):
        HTMLParser.__init__(self)
        self.anchors = []
        self.csrf = ""
        self.found_csrf = False
        self.flags = []
    

    #handler for start tag. pays attention to anchors / inputs to grab important info
    def handle_starttag(self, tag, attrs):
        if tag == "a":
            for attr in attrs:
                if attr[0] == "href":
                    if("logout" not in attr[1] and "." not in attr[1] and "login" not in attr[1]):
                        #add to the list to crawl
                        self.anchors.append(attr[1])
        if tag == "input":
            for attr in attrs:
                if attr[1] == "csrfmiddlewaretoken":
                    #got it, take this one
                    self.found_csrf = True
                if(attr[0] == "value" and self.found_csrf):
                    self.csrf = attr[1]
                    self.found_csrf = False
    def handle_data(self, data):
        if "FLAG" in data:
            #add flag to list
            self.flags.append(data.split(":")[1][1:])


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()
    sender = Crawler(args)
    sender.run()
